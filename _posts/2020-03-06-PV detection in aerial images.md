Detecting Solar PV in Aerial Imagery
------------------------------------

Abdullah AlOthman, Felipe Buchbinder, Joseph Krinke, Jing Jing Shi

This Project was done with my group members Abdullah AlOthman, Felipe Buchbinder, Joseph Krinke.

Abstract
--------

The usage of solar PV arrays has been increasing in the United States,
but it is difficult to obtain comprehensive and granular information on
solar array locations. Current solar PV installation information across
the United States would be useful for energy policymakers, government
officials, and utility companies. In this paper, the performance of five
different artificial intelligence algorithms were compared on
identifying solar panels in a set of satellite aerial image data. These
algorithms included convolutional neural networks with and without
transfer learning and support vector machines (SVMs) in conjunction with
histogram of oriented gradients (HOG) or Canny Edge Detection. A
convolutional neural network with weighted voting achieved the best
result with an area under the curve (AUC) of 0.97 on the test data. This
approach demonstrates a potential method for quickly obtaining
information on the location of PV arrays.

Introduction
------------

Humans all need electrical energy to survive and to live comfortably.
Each human requires approximately 3,000W of energy per day \[1\].
Consequently, looking for sources of renewable energy is needed.
Renewable energy refers to energy generated by wind, the sun, the
movement of water, or the burning of biomass. They have major
technological advantages compared to traditional fossil fuel energy
\[2\] such as being clean source, large-scale, higher energy transfer
efficiency, and also renewable. Among those renewable energy sources,
solar energy is the one that is most appealing to researchers and has
already been investigated into the application stage. Solar energy is a
great alternative to fossil fuels. Solar radiation is readily accessible
in almost all areas around the world, while wind and hydroelectric
energy require certain geographic conditions. The conversion rates of
solar energy to electrical energy are relatively high and have been
investigated for more than 40 years\[3\].There are currently three major
forms of solar energy: solar thermal, solar photovoltaic (PV) and
photovoltaic thermal (PV/T) \[4\] Solar thermal converts solar radiation
mostly to heat, and solar PV is a technology that converts solar energy
into electrical energy using semiconductors \[5\]. Hybrid PV/T modules
generate heat and electricity simultaneously. Solar PV is a preferable
approach since the storage of electrical energy is easier compared to
thermal energy. Moreover, solar PV could take advantage of the current
energy transmission system, making the transition from natural gas
energy sources to solar energy sources easier and cheaper. However, PV
modules convert only around 10\%-20\% of the solar radiation into
electrical energy, therefore, a further investigation of improving PV
modules' efficiency is required.

Currently, solar PVs are widely used in building applications, and
gathering information on solar PV usage is extremely important to study
potential issues or improvements. However, traditional surveys and
utility interconnection filings are not suitable in this case since they
include large amounts of data that would be complex to merge and
analyze. Such traditional approaches are ultimately slow and expensive
\[5\]. Additionally, it is possible that solar PV data is entirely
unavailable for certain regions. With the development of public
available high-resolution satellite collected images, a faster and more
accurate method could be created to collect solar PV information. A
recent research pointed out that solar PV installed by the government
could be solutions to energy poverty in low-income families\[6\].
Gathering current solar PV installations information across all areas
becomes increasingly important for the government to evaluate
past-installation, get energy consumption feedback, and determine
possible smart technologies needed.

Satellite data has opened up a new way of us looking into the world, but
it also brings in new challenges such as extracting useful information
from massive data. In this report, potential computer algorithms were
explored to automatically recognize PV panel information from
high-resolution color aerial imagery. Accurately identifying PV panels
from aerial imagery could assist researchers in identifying global solar
panel placement trends as well as helping determine if panels are being
optimally placed.

Background
----------

The first problem that needs to be solved in this analysis is image
classification. Image classification is a complex supervised learning
problem, and has been an important topic in the field of computer
vision. Examples of image classification range from binary
classification like determining if there is a dog in a picture to
multiclass classification such as identifying a handwritten digit. An
image classification problem is usually solved by pre-processing images,
extracting features from images, training models and classifying the
target object. Support vector machines (SVMs) have been used for
hyper-spectral data classification\[7\]. Camps-Valls\[7\] and his
colleagues trained SVM models using AVIRIS dataset and they pointed out
that SVMs performed excellent regarding accuracy, computational cost,
noises, and ensured sparsity. Kumar and his colleagues\[8\] combined a
random forest classifier with artificial neural networks (ANNs), and
this fusion method achieved better classification accuracy.
Convolutional neural networks (CNNs) have been a popular approach in
computer vision, mainly because they can automatically discover related
features in image classification problems\[9\].

Computer algorithms have been used to identify solar panels in the past.
Jordan M. Malof and his colleagues suggested a new approach to detect
rooftop solar PV in aerial imagery using computer vision algorithms
\[10\].They used house images from the U.S. Geological Survey (USGS).
The imagery was collected over the city of Lemoore, CA during 2014 at a
resolution of 0.3m, and with 8-bit resolution in each color channel.
They manually chose 100 images, 50 that contained rooftop PV
installations and 50 that did not contain rooftop PV installations. Each
figure was cropped to a rectangular region containing the rooftop and
the surrounding area. The decision algorithm consisted of two parts:
prescreening and feature processing. Prescreening first converts all
images into grayscale and reduces the region by removing the lowest 30\%
of pre-screener confidence values. The features examined here include
foreground color, background color, and shape features. Then an SVM
classifier was utilized to generate the final list of detected regions.
They suggested that their work could be possibly used to estimate power
capacity and energy production in a fast, scalable and cheap method.

From their work, it can be concluded that the first step of using aerial
imagery data in solar PV involves feature extraction, classifier, and
object detection. Feature extractions can be accomplished by several
different algorithms, however, the main principle in feature extraction
is extracting image features, and effectively mapping the 3 channel
(RGB) images into lower-dimensional data. As for classifiers, besides
the SVM mentioned above, Jordan M. Malof and his colleagues used a
trained random forest classifier into the same dataset\[5\], they found
out that this classifier was also effective at detecting PV panels in
aerial images.

Another study, conducted by researchers at Stanford University, aimed to
tackle a similar problem- determining the distribution of solar panels
using satellite imagery\[11\]. They use a single convolutional neural
network approach. Ultimately, the researchers used their algorithm to
try to create a national solar panel database. They then used this
database to identify demographic and economic features that were
associated with the presence of solar panels. These predictors were then
used to produce a model to predict the presence of solar panels. Perhaps
most interestingly, they found "a solar radiation threshold (4.5
kWh/m^2^/day) above which the solar deployment is triggered" and that
solar panel usage is inversely correlated with the gini index and
positively correlated with household income. This study suggests that
solar panels are disproportionately located in high-income areas with
little socioeconomic diversity. Consequently, more information on the
localization of solar panels may lead to insight into economic
inequality in the United States and access to renewable energy sources.

Data
----

The data that is used in this analysis is similar to the data mentioned
in the background section. The images are of 101\*101 pixels and are in
3 channels (RGB). All the images contain the rooftop of houses and some
surrounding areas. The data is divided into training and test sets, with
the training data containing 1500 images and test containing 558 images.
The training data contains 505 examples with solar panels present and
995 examples without solar panels. The decision algorithms were trained
on training data and then the algorithm performance were evaluated on
test data.

There are a number of challenges inherent to the problem of image
classification. Image data is typically very large, with a number of
features spread over multiple RGB channels. This becomes more of an
issue given the small size of the data compared to the dimensionality of
the data. The sparsity of this data could potentially lead to
overfitting, so images were pre-processed before modeling. Two different
forms of feature extraction were employed for use in the SVM models:
Canny edge detection and histogram of oriented gradients (HOG). A
theoretical justification of these approaches can be found in the
methods section. The figure below shows examples of each class after
being subjected to each type of pre-processing.

<img src="/assets/img/pv_detection/image1.png" >


Figure 1. Positive and Negative Images With Various Processing
Techniques

It appears that solar panel images generally have more edges overall.
This makes sense, as each panel has its own set of boundaries. Models
that attempt to fit using this characteristic may perform well. Other
scenarios must also be considered that could cause a large number of
edges in an image. This could include large amounts of trees, a roof
with many angles, or objects like cars or sheds.

Methods
-------

This study aims to build a model to identify if a satellite image
contains solar panels. The data used to build the model are pre-labelled
images. Methodologies vary both in the way they pre-process the data and
what models they apply to the processed data.

Four different methods will be discussed in this paper:

1.  Pre-processing data using a HOG approach and, subsequently,
    classifying features using an SVM classifier

2.  Pre-processing data using Canny Edge Detection and classifying
    features using an SVM classifier \[Baseline Model\]

3.  Convolutional Neural Network

4.  Convolutional Neural Network with Transfer Learning

<img src="/assets/img/pv_detection/image2.png" >
Figure 2. Diagram of Modeling Process

### HOG-SVM

A HOG transform identifies pixels whose values are substantially
different than their neighbouring pixels, thereby suggesting that they
mark the edge of some object \[12\].The intensity of most things changes
smoothly and continuously. When two different objects are juxtaposed,
however, the intensity of their pixels may change abruptly in their
borders. Hence, identifying large gradients in pixel intensity is an
approach by which edges may be recognized. This, in turn, can be used to
convey information about the existence of a solar panel in an image.

An SVM classifier separates classes by identifying the threshold which
maximizes the distance between both classes to the threshold. One can
think of identifying two parallel thresholds which separate both classes
while being as far apart from each other as possible. SVM has been
successfully employed in a myriad of classification problems from fields
as diverse as text analysis\[13\], green energy research\[14\] finance
\[15\]and oncology\[16\].

Both HOG and SVM are widely used techniques, both individually \[17\]
and combined \[18\]. Furthermore, one should add that SVMs have been
successfully employed to predict the existence of photovoltaic panels in
satellite aerial imagery\[10\]. One must acknowledge that this paper
differs from Malof *et al* \[10\], who were trying to locate
photovoltaic panels in aerial images, this paper is trying to identify
if such a panel is present. These important differences notwithstanding,
Malof *et al* \[10\]. were able to use an SVM to achieve a 94\% correct
prediction rate. Though Malof *et al* \[10\]. did not use HOG as a
pre-processing state for their analysis, literature from other fields
offers examples of how combining HOG with SVM can be successful. Bakheet
\[19\] achieved 98\% sensitivity and 96\% specificity when combining these
techniques to identify malignant melanomas from images of a patient\'s
skin.

A less impressive result was obtained by Sun and Watada \[20\], who
combined HOG and SVM to identify pedestrians and vehicles in a traffic
light scene. These authors obtained a 75\% correct detection rate. Cao,
Wu and Li \[21\] use the same approach to identify vehicles based on
low-altitude aerial images but arrive at a 90\% correct detection rate
with a 10\% false positive rate. Dadi & Pillutla \[18\] used a
combination of HOG and SVM for facial recognition to improve on the
performance of previous models. There is also evidence in literature
that suggests that HOG and SVM perform better than other approaches with
noisy data. Radman, Zainal and Suandi \[22\] combined HOG and SVM to
identify pixels which correspond to human irises in pictures gathered in
an unconstrained environment. They find their method to improve the
previous benchmark by 11\% . The combination of HOG and SVM has been
found to significantly outperform previous methods in some fields.
Hence, the combination of HOG and SVM as an image recognition algorithm
is well documented in literature as an approach that produces successful
results. While this is not the case in solar panel imaging, where neural
networks are the unquestionable benchmark, this makes a case as to why
combining HOG and SVM is a rational choice of a non-neural network based
model.

Following Lai and Teoh \[23\], a HOG transformation was performed using
cells of sizes 16 by 16 and blocks of sizes 2 by 2. For classification,
an SVM algorithm was used with a regularization parameter of 10. The
output in all models that developed was the predicted probability that
the image pertained to the class of images that contained a solar panel.
The performance of the model was evaluated using 5-fold stratified
cross-validation and analysing the receiver operating characteristic
(ROC) curve.

### Canny Edge Detection SVM

The second approach used a different type of image pre-processing called
Canny Edge Detection \[24\]. Canny edge detection is a process that
extracts edges from an image. This technique does not work well with
high amounts of noise. The first step is gaussian filtering, which
"blurs" the image and reduces noise while keeping the edges intact.
After filtering, the intensity gradient of the image is calculated.
Edges are associated with changes in pixel intensity, so this gradient
allows us to identify preliminary edges. However, at this point, the
image produced has edges that vary wildly in thickness. Thinner and more
consistent edges are better for image classification, so the algorithm
corrects for this using non-maximum suppression. Non-maximum suppression
scans the image to find pixels that are the local maxima in their
neighborhood in the direction of the gradient. If the pixel is not a
maximum point it is reduced to zero. Finally, hysteresis thresholding is
applied; hysteresis thresholding examines the gradient values along
connected edges to determine if an edge is intense enough to remain. An
edge with values all above or below a certain threshold is immediately
kept or discarded. Cases where part of the edge are stronger than others
are more complex. In this case, the algorithm keeps the edge if any
connected portion of it exceeds the top intensity threshold. This
eliminates false edges while making sure real edges with varying
intensities along their lengths are included.

Canny edge detection, perhaps unsurprisingly, has been heavily used in
applications where the edge of an image is of high importance. Such
applications include measuring the contraction of heart cells,
determining the thickness of retinal layers, or using computer vision to
develop automated assembly-line robots \[24-26\]. Canny edge detection
has also been used in problems similar to this solar panel
identification project; one study applied the algorithm to remote
sensing images \[27\]. Remote sensing images are images of the earth's
surface collected at a distance by satellite or aircraft. Such images
may be generated by a variety of sources including sonar, radar, or
traditional photography. Ali and other researchers applied the Canny
algorithm to satellite photographs and produced results that were
"robust and achieved a very high enhancement level" \[27\].

Canny edge detection was applied to this report since others had used it
successfully on satellite imagery,. This technique was also used because
it appears that solar panels have obvious and straight edges. It was
theorized that a solar panel on a residential home (after edge
detection) could look like boxes inside a box. This pattern could
provide a feature for usage in an SVM.

### Transfer Learning

Transfer learning is the process of getting a neural network which has
already been trained to solve one generalized version of a problem and
using it (or some portion of it) to solve a different problem in the
same domain. In the case of transfer learning from a CNN model on
computer vision problems, Mehra \[28\] justifies it by arguing that the
initial layers of a CNN capture general features which are not specific
to any particular problem set and which may therefore be useful in many
different settings. By employing the initial layers of a CNN that
already learned to identify these features, a much smaller subset of
features remain to be learned, namely, only the features that are
particular to this case.

VGG16 was chosen as the base model to transfer from because research
suggests that this approach achieves higher prediction performances than
similar CNNs trained without transfer learning \[28\]. It should be
mentioned, however, that there are instances in literature that report
transfer learning not to have had significant impact in prediction
performance. One such example is offered by Malof \[29\].

Transfer learning is often useful because that the earlier layers of a
CNN encompass information on general features applicable to a myriad of
diverse problem settings, then it could be concluded that the specific
features of the given problem must lie in the final layers of the CNN.
It therefore makes sense to substitute the final layers of the
pre-trained CNN by layers which are not trained, and whose weights will
be estimated directly from the images specific to the problem being
addressed.

The last three layers of VGG16 were removed and four additional layers
were added. The first of these layers performs a mean pooling on the
data. The two subsequent layers are fully connected layers with ReLu
activation functions and dropout rates of 0.5 and 0.3 respectively.
Finally, a classification layer was added with a sigmoid activation
function.

The neural network was set to minimize a cross-entropy loss function
using the Adam optimization algorithm \[30\]. To avoid overfitting, the
validation loss was monitored after every epoch and stop training the
model when the model does not improve for 2 consecutive epochs.

### Bagged Convolutional Neural Networks 

CNNs are one of the most widely used and successful algorithms in visual
recognition tasks \[31\]. CNNs' popularity stems not only from its
accuracy, but also from its ability to create its own features, so to
speak. In the words of Zagoruyko and Komodakis\[32\] , CNNs can "learn
directly from image data (i.e., without resorting to manually-designed
features) a general similarity function for comparing image patches,
which is a task of fundamental importance for many computer vision
problems."

There is no need to feature-engineer the input image using HOG or other
similar techniques in order to identify edges, corners or other features
for this analysis\[33\]. Indeed, according to Schwartz-Ziv and
Tishby\[34\] , most of CNN\'s training time is spent identifying these
features. In their own words, most of the training time is spent on
"compression of the input to efficient representation and not on fitting
the training labels"\[34\].

Moreover, CNNs retain information on each pixel's location. The
convolving kernels that give the network its name captures the spatial
information inherent in the image (The reader may find a more thorough
discussion on the advantages of CNN by referring to Chatfield \[35\] *et
al.* ).
<img src="/assets/img/pv_detection/image3.png" >

Figure 3. Network

<img src="/assets/img/pv_detection/image4.png" >


Figure 4. Convolution Block Diagram

The dataset is relatively small for an object-detection problem. Given
its high flexibility, a CNN model could easily overfit to the training
set. Consequently, a bagging approach using CNNs was employed. The
approach began by building a CNN following the architecture shown in
Figure 3. The training dataset was split into 5 overlapping subsets. A
model was trained for 50 epochs on an augmented version of each subset
where image transformations (rotation, shifting, flipping, and cropping)
are employed. The models are set to minimize the binary cross entropy
using the Adam optimizer with a learning rate of 1e-3 which decays by
2e-5 after each epoch.

The 5 models are then aggregated to further reduce variance and prevent
overfitting, which lead to more stable and generalizable predictions.
One can observe the high variation among individual CNNs in Figure 7.
This stands in contrast to the stability and accuracy of the bagged
model.

### Weighted Voting

In the bagging CNN model, a series of weak classifiers were created
which, taken together (as an ensemble), produced a better result than
each classifier individually. There is no reason to limit this approach
to CNNs alone. Indeed, rather than considering the models discussed so
far as final models, each of them was treated as a weak learner and
combined them all into an ensemble, thereby producing an additional
model called the weighted voting model. Specifically, this model
consists of aggregating the predictions of the three previous
non-baseline models: bagged CNN, transfer-learning CNN and HOG-SVM. The
predictions were aggregated by averaging them with weights that are
proportional to their performance and having them vote on the class of
the input image. This means that the best model will still have the
highest impact on the confidence score, while other models act as
supplementary aids. While the model's results will be discussed in the
following section, it should be noted that the bagged CNN performs the
best of the individual models(figures 5 and 6). This means that the
weight ascribed to it when constructing the weighted voting model is
larger than the weights on the other models.

Results
-------

In this section, the results of the different methodologies that are
employed to identify solar panels in aerial images will be presented and
compared. Figure 5 presents the ROC curves associated with the five
different methods. The model with the highest area under curve(AUC) is
the weighted voting model(AUC = 0.970). This model is a composition of
the remaining models, so its superior performance essentially shows that
one can outperform all other models by combining them.

It is noteworthy, however, that the weighted voting model's ROC curve is
fairly similar to the bagged CNN (AUC = 0.955). This is due to the fact
that all other models perform significantly worse than the bagged CNN,
so this model receives the highest weight in the voting which composes
the weighted voted CNN. Hence, it appears that the bagged CNN is
responsible for most of the efficiency of the final model, but
occasionally commits misclassifications that can be corrected by the
remaining models.

<img src="/assets/img/pv_detection/image5.png" >


Figure 5. Model Performance Comparison: ROC Curves

<img src="/assets/img/pv_detection/image6.png" >


Figure 6. Model Performance Comparison: Precision-Recall Curves

Given that the bagged CNN was the most relevant contributor to the
best-performing model, it's insightful to consider the performance of
each CNN used in the bagging (figure 7). Most subsets yield AUCs
comparable to the baseline model, so bagging improves the performance of
the overall CNN. Indeed, the reason why used bagging was precisely to
prevent overfitting. The dispersion of ROC curves in Figure 7 are
suggestive of the sensitivity of model performance to training data and,
therefore, of the model's propensity to overfit. The bagged model
prevents that and, as expected, achieves a better predictive capacity
and a higher AUC than almost all individual curves. This predictive
trend can also be seen in the precision-recall curves and confusion
matrices (figure 6, figure 8).

<img src="/assets/img/pv_detection/image7.png" >


Figure 7. CNN Bagging Model Comparison

<img src="/assets/img/pv_detection/image8.png" >

Figure 8. Confusion Matrices of Different Models

From the confusion matrices shown in figure 8, it could be concluded
that models including CNNs produced higher accuracy compared to the SVM
models. 33\% of images that contained solar panels were identified as not
having any in Canny-SVM, and this was also a problem in HOG-SVM, which
suggested that SVMs might struggle with finding all solar panels. CNN
models performed better in general, however, they produced more false
positives. This indicated that CNNs might mistake other similar features
as a false solar panel.

As previously discussed when analysing Figure 5, weighting the votes of
all models yields the best model. The majority of such votes is
attributed to the best performing model, namely, the bagging CNN,
discussed in Figure 7. The strengths and weaknesses of the two best
performing models will be discussed proceedingly. Namely, we seek to
gain a better understanding of the kinds of images wherein the models
yield bad predictions. To this end, cases which would (for a wide range
of possible thresholds) be labeled as true positives, true negatives,
false positives and false negatives will be considered. Some of these
cases were presented in Figures 9 and 10, though it is important to
mention that these are only representative examples of a much larger set
of pictures which were analysed to derive the conclusions.

The HOG-SVM models produced many false-positive results when presented
with images that had angular roofs. These angles, like solar panels,
have hard edges that may be misinterpreted by the model. The
false-negative results primarily occurred when the region of solar
panels was small relative to the overall image.

<img src="/assets/img/pv_detection/image9.png" >


Figure 9. HOG Misclassification

The voting model had difficulties in rooftops which presented angles or
dark shades. The darker pixels might have been interpreted by the
algorithm as a solar panel, thereby leading the algorithm to mistakenly
classify the image as a having a solar panel. Figure 10 shows two false
positive examples where one can clearly distinguish a darker region of
rooftops as a result of roofs not being perfectly flat.

Moreover, the misclassified images often present rooftops with lots of
small objects. The algorithm may be identifying the presence of objects
on rooftops and concluding that they are solar panels when, in reality,
they are not. Likewise, when solar panels represent a small portion of
the roof, the algorithm mistakes these images for false negatives.

<img src="/assets/img/pv_detection/image10.png" >


Figure 10. Voting Sample Image Misclassification

If these findings were considered conjointly, it seems the algorithm is
being tricked to think that large objects on the roof are solar panels,
whereas small objects on the roof are not. It seems therefore to be
implicitly considering that solar panels must have a certain size which
is not consistent with reality. Addressing this issue is an improvement
which needs to be sought in future versions of the algorithms used in
this report.

Conclusion
----------

In this paper a variety of predictive algorithms were applied and
pre-processing techniques to the problem of identifying if a given
satellite image contains a solar PV array. These algorithms included
convolutional neural networks with and without transfer learning and
SVMs in conjunction with HOG or Canny Edge Detection. A weighted voting
model using aggregate predictions from a subset of the models produced
the best result and achieved an AUC on the test data of 0.970. This
model presents a method by which one could generate information on solar
panel locations. This could also be used to identify global solar panel
placement trends as well as to help determine if panels are being
optimally placed. Future work could focus on other problems, such as
determining the solar PVs' energy efficiency, examining household energy
consumption, or merging predicted panel locations with other geographic
or demographic information.



References 
-----------

> \[1\] A. Khare, \"A critical review on the efficiency improvement of
> upconversion assisted solar cells,\" *Journal of Alloys and
> Compounds,* vol. 821, p. 153214, 2020/04/25/ 2020, doi:
> [[https://doi.org/10.1016/j.jallcom.2019.153214]{.underline}](https://doi.org/10.1016/j.jallcom.2019.153214).
>
> \[2\] H. Lund, \"Renewable energy strategies for sustainable
> development,\" *Energy,* vol. 32, no. 6, pp. 912-919, 2007/06/01/
> 2007, doi:
> [[https://doi.org/10.1016/j.energy.2006.10.017]{.underline}](https://doi.org/10.1016/j.energy.2006.10.017).
>
> \[3\] A. J. Bard, \"Design of semiconductor photoelectrochemical
> systems for solar energy conversion,\" *The Journal of Physical
> Chemistry,* vol. 86, no. 2, pp. 172-177, 1982/01/01 1982, doi:
> 10.1021/j100391a008.
>
> \[4\] C. Good, I. Andresen, and A. G. Hestnes, \"Solar energy for net
> zero energy buildings -- A comparison between solar thermal, PV and
> photovoltaic--thermal (PV/T) systems,\" *Solar Energy,* vol. 122, pp.
> 986-996, 2015/12/01/ 2015, doi:
> [[https://doi.org/10.1016/j.solener.2015.10.013]{.underline}](https://doi.org/10.1016/j.solener.2015.10.013).
>
> \[5\] J. M. Malof, K. Bradbury, L. M. Collins, and R. G. Newell,
> \"Automatic detection of solar photovoltaic arrays in high resolution
> aerial imagery,\" *Applied Energy,* vol. 183, pp. 229-240, 2016/12/01/
> 2016, doi:
> [[https://doi.org/10.1016/j.apenergy.2016.08.191]{.underline}](https://doi.org/10.1016/j.apenergy.2016.08.191).
>
> \[6\] J. Lee and M. M. Shepley, \"Benefits of solar photovoltaic
> systems for low-income families in social housing of Korea: Renewable
> energy applications as solutions to energy poverty,\" *Journal of
> Building Engineering,* vol. 28, p. 101016, 2020/03/01/ 2020, doi:
> [[https://doi.org/10.1016/j.jobe.2019.101016]{.underline}](https://doi.org/10.1016/j.jobe.2019.101016).
>
> \[7\] G. Camps-Valls and L. Bruzzone, \"Kernel-based methods for
> hyperspectral image classification,\" *IEEE Transactions on Geoscience
> and Remote Sensing,* vol. 43, no. 6, pp. 1351-1362, 2005, doi:
> 10.1109/TGRS.2005.846154.
>
> \[8\] A. S. Kumar and K. Majumder, \"Information fusion in tree
> classifiers,\" *International Journal of Remote Sensing,* vol. 22, no.
> 5, pp. 861-869, 2001.
>
> \[9\] E. Maggiori, Y. Tarabalka, G. Charpiat, and P. Alliez,
> \"Convolutional Neural Networks for Large-Scale Remote-Sensing Image
> Classification,\" *IEEE Transactions on Geoscience and Remote
> Sensing,* vol. 55, no. 2, pp. 645-657, 2017, doi:
> 10.1109/TGRS.2016.2612821.
>
> \[10\] J. M. Malof, H. Rui, L. M. Collins, K. Bradbury, and R. Newell,
> \"Automatic solar photovoltaic panel detection in satellite imagery,\"
> in *2015 International Conference on Renewable Energy Research and
> Applications (ICRERA)*, 22-25 Nov. 2015 2015, pp. 1428-1431, doi:
> 10.1109/ICRERA.2015.7418643.
>
> \[11\] J. Yu, Z. Wang, A. Majumdar, and R. Rajagopal, \"DeepSolar: A
> Machine Learning Framework to Efficiently Construct a Solar Deployment
> Database in the United States,\" *Joule,* vol. 2, no. 12, pp.
> 2605-2617, 2018/12/19/ 2018, doi:
> [[https://doi.org/10.1016/j.joule.2018.11.021]{.underline}](https://doi.org/10.1016/j.joule.2018.11.021).
>
> \[12\] N. Feng, D. Delhomme, Y. LeCun, F. Piano, L. Bottou, and P. E.
> Barbano, \"Toward automatic phenotyping of developing embryos from
> videos,\" *IEEE Transactions on Image Processing,* vol. 14, no. 9, pp.
> 1360-1371, 2005, doi: 10.1109/TIP.2005.852470.
>
> \[13\] S. Tong and D. Koller, \"Support Vector Machine Active Learning
> With Applications To Text Classification,\" *The Journal of Machine
> Learning Research,* vol. 2, pp. 45-66, 12/22 2001, doi:
> 10.1162/153244302760185243.
>
> \[14\] O. Kramer and F. Gieseke, \"Short-Term Wind Energy Forecasting
> Using Support Vector Regression,\" in *Soft Computing Models in
> Industrial and Environmental Applications, 6th International
> Conference SOCO 2011*, Berlin, Heidelberg, E. Corchado, V. Snášel, J.
> Sedano, A. E. Hassanien, J. L. Calvo, and D. Ślȩzak, Eds., 2011//
> 2011: Springer Berlin Heidelberg, pp. 271-280.
>
> \[15\] S. Maldonado, J. Pérez, and C. Bravo, \"Cost-based feature
> selection for Support Vector Machines: An application in credit
> scoring,\" *European Journal of Operational Research,* vol. 261, no.
> 2, pp. 656-665, 2017/09/01/ 2017, doi:
> [[https://doi.org/10.1016/j.ejor.2017.02.037]{.underline}](https://doi.org/10.1016/j.ejor.2017.02.037).
>
> \[16\] S. Huang, N. Cai, P. P. Pacheco, S. Narrandes, Y. Wang, and W.
> Xu, \"Applications of Support Vector Machine (SVM) Learning in Cancer
> Genomics,\" (in eng), *Cancer Genomics Proteomics,* vol. 15, no. 1,
> pp. 41-51, Jan-Feb 2018, doi: 10.21873/cgp.20063.
>
> \[17\] R. Kapoor, R. Gupta, L. H. Son, S. Jha, and R. Kumar,
> \"Detection of Power Quality Event using Histogram of Oriented
> Gradients and Support Vector Machine,\" *Measurement \$V 120,* pp.
> 52-75, 2018.
>
> \[18\] H. S. Dadi and G. K. M. Pillutla, \"Improved face recognition
> rate using HOG features and SVM classifier,\" *IOSR Journal of
> Electronics and Communication Engineering,* vol. 11, no. 4, pp. 34-44,
> 2016.
>
> \[19\] S. Bakheet, \"An svm framework for malignant melanoma detection
> based on optimized hog features,\" *Computation,* vol. 5, no. 1, p. 4,
> 2017.
>
> \[20\] D. Sun and J. Watada, \"Detecting pedestrians and vehicles in
> traffic scene based on boosted HOG features and SVM,\" in *2015 IEEE
> 9th International Symposium on Intelligent Signal Processing (WISP)
> Proceedings*, 15-17 May 2015 2015, pp. 1-4, doi:
> 10.1109/WISP.2015.7139161.
>
> \[21\] X. Cao, C. Wu, P. Yan, and X. Li, \"Linear SVM classification
> using boosting HOG features for vehicle detection in low-altitude
> airborne videos,\" in *2011 18th IEEE International Conference on
> Image Processing*, 11-14 Sept. 2011 2011, pp. 2421-2424, doi:
> 10.1109/ICIP.2011.6116132.
>
> \[22\] A. Radman, N. Zainal, and S. A. Suandi, \"Automated
> segmentation of iris images acquired in an unconstrained environment
> using HOG-SVM and GrowCut,\" *Digital Signal Processing,* vol. 64, pp.
> 60-70, 2017/05/01/ 2017, doi:
> [[https://doi.org/10.1016/j.dsp.2017.02.003]{.underline}](https://doi.org/10.1016/j.dsp.2017.02.003).
>
> \[23\] C. Q. Lai and S. S. Teoh, \"A review on pedestrian detection
> techniques based on Histogram of Oriented Gradient feature,\" *2014
> IEEE Student Conference on Research and Development, SCOReD 2014,*
> 03/30 2015, doi: 10.1109/SCORED.2014.7072948.
>
> \[24\] S. Luo, J. Yang, Q. Gao, S. Zhou, and C. a. A. Zhan, \"The edge
> detectors suitable for retinal OCT image segmentation,\" *Journal of
> healthcare engineering,* vol. 2017, 2017.
>
> \[25\] B. K. Balabantaray, P. Jha, and B. B. Biswal, *Application of
> edge detection algorithm for vision guided robotics assembly system*
> (Sixth International Conference on Machine Vision (ICMV 13)). SPIE,
> 2013.
>
> \[26\] J. T. Goulart, R. A. Bassani, and J. W. M. Bassani,
> \"Application based on the Canny edge detection algorithm for
> recording contractions of isolated cardiac myocytes,\" *Computers in
> Biology and Medicine,* vol. 81, pp. 106-110, 2017/02/01/ 2017, doi:
> [[https://doi.org/10.1016/j.compbiomed.2016.12.014]{.underline}](https://doi.org/10.1016/j.compbiomed.2016.12.014).
>
> \[27\] M. Ali and D. Clausi, *Using the Canny edge detector for
> feature extraction and enhancement of remote sensing images*. 2001,
> pp. 2298-2300 vol.5.
>
> \[28\] Shallu and R. Mehra, \"Breast cancer histology images
> classification: Training from scratch or transfer learning?,\" *ICT
> Express,* vol. 4, no. 4, pp. 247-254, 2018/12/01/ 2018, doi:
> [[https://doi.org/10.1016/j.icte.2018.10.007]{.underline}](https://doi.org/10.1016/j.icte.2018.10.007).
>
> \[29\] J. M. Malof, L. M. Collins, and K. Bradbury, \"A deep
> convolutional neural network, with pre-training, for solar
> photovoltaic array detection in aerial imagery,\" in *2017 IEEE
> International Geoscience and Remote Sensing Symposium (IGARSS)*, 2017:
> IEEE, pp. 874-877.
>
> \[30\] D. Kingma and J. Ba, \"Adam: A Method for Stochastic
> Optimization,\" *International Conference on Learning
> Representations,* 12/22 2014.
>
> \[31\] Y. Sun, B. Xue, M. Zhang, and G. G. Yen, \"Evolving deep
> convolutional neural networks for image classification,\" *IEEE
> Transactions on Evolutionary Computation,* 2019.
>
> \[32\] S. Zagoruyko and N. Komodakis, \"Learning to compare image
> patches via convolutional neural networks,\" in *Proceedings of the
> IEEE conference on computer vision and pattern recognition*, 2015, pp.
> 4353-4361.
>
> \[33\] E. Rezende, G. Ruppert, T. Carvalho, A. Theophilo, F. Ramos,
> and P. De Geus, \"Malicious Software Classification Using VGG16 Deep
> Neural Network's Bottleneck Features,\" 2018, pp. 51-59.
>
> \[34\] R. Shwartz-Ziv and N. Tishby, \"Opening the Black Box of Deep
> Neural Networks via Information,\" 03/02 2017.
>
> \[35\] K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman,
> \"Return of the devil in the details: Delving deep into convolutional
> nets,\" *arXiv preprint arXiv:1405.3531,* 2014.
